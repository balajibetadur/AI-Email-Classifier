{
    "time" : {
        "1": "short time",
        "2": "moderate time"
    },
    
    
    "parameters" : {
        "1" : ["Test Size","input","20","Enter test size. ex: 20 for 20% test set"],
        "2" : ["Grid Search","select",["No","Yes"],"Tests for different hyperparameter values (Increases training time)"],
        "3" : ["Number of Estimators", "input","100","(Number fo Trees) Suggested value is between 64 - 128 trees. Huge value may increase training time"],
        "4" : ["Maximum Iterations","input","100","Maximum number of iterations taken for the solvers to converge"],
        "5" : ["Min Samples Split","input","2","The minimum number of samples required to split an internal node"],
        "6" : ["Min Samples Leaf", "input", "1", "The minimum number of samples required to be at a leaf node."],
        "7" : ["alpha", "select",["1","0", "0.1", "0.01", "0.001", "0.0001", "0.00001"], "Additive (Laplace/Lidstone) smoothing parameter(0 for no smoothing)"],
        "8" : ["loss", "select", ["hinge", "log", "modified_huber", "squared_hinge", "perceptron", "epsilon_insensitive"], "The loss function to be used" ],
        "9" : ["penalty", "select", ["l1","l2","elasticnet"], "The penalty (aka regularization term) to be used"],
        "10": ["alpha_svm", "select",["0.001","0.01","0.0001"], "Constant that multiplies the regularization term."],
        "11": ["Maximum Iteration","input","5", "The maximum number of passes over the training data (aka epochs)"]
    },
    


    "models" : {

        "1" : {
            "1" : ["Logistic Regression",["1","2","4"]],
            "2" : ["Decesion Tree Classifier", ["1","2","3"]],
            "3" : ["Random Forest Classifier",["1","2","3","5","6"]],   
            "4" : ["Linear Support Vector Machine",["1","2","8","9","10","11"]],   
            "5" : ["Naive Bayes Classifier",["1","2","7"]]
        },
        
        "2" : {
            "1" : ["Artificial Neural Networks",["7"]],
            "2" : ["LSTM",["7"]],
            "3" : ["BERT",["6","7"]]
        }
    }
}